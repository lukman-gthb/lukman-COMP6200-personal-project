{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Genre of Books from Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/cisitu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/cisitu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this analysis, a set of book summaries from [CMU Book Summaries Corpus](http://www.cs.cmu.edu/~dbamman/booksummaries.html) is used. The dataset contains a large number of summaries and include the genre information of the books taken from Freebase. Each book can have more than one genre and there are 227 genres listed in total. In order to simplify the problem, only a small number of target genres that occur frequently are selected and the experiment only uses the book with selected genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = ['wid', 'fid', 'title', 'author', 'date', 'genres', 'summary']\n",
    "\n",
    "books = pd.read_csv(\"data/Portfolio3files/booksummaries.txt\", sep=\"\\t\", header=None, names=names, keep_default_na=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next filter the data so that only our target genre labels are included and we assign each text to just one of the genre labels.  It's possible that one text could be labelled with two of these labels (eg. Science Fiction and Fantasy) but we will just assign one of those here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8954, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_genres = [\"Children's literature\",\n",
    "                 'Science Fiction',\n",
    "                 'Novel',\n",
    "                 'Fantasy',\n",
    "                 'Mystery']\n",
    "\n",
    "# create a Series of empty strings the same length as the list of books\n",
    "genre = pd.Series(np.repeat(\"\", books.shape[0]))\n",
    "# look for each target genre and set the corresponding entries in the genre series to the genre label\n",
    "for g in target_genres:\n",
    "    genre[books['genres'].str.contains(g)] = g\n",
    "\n",
    "# add this to the book dataframe and then select only those rows that have a genre label\n",
    "# drop some useless columns\n",
    "books['genre'] = genre\n",
    "genre_books = books[genre!=''].drop(['genres', 'fid', 'wid'], axis=1)\n",
    "\n",
    "genre_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Children's literature</th>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novel</th>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  author  date  summary\n",
       "genre                                              \n",
       "Children's literature   1092    1092  1092     1092\n",
       "Fantasy                 2311    2311  2311     2311\n",
       "Mystery                 1396    1396  1396     1396\n",
       "Novel                   2258    2258  2258     2258\n",
       "Science Fiction         1897    1897  1897     1897"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "books_distribution_df = genre_books.groupby('genre').count()\n",
    "display(books_distribution_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAHGCAYAAABuJ2HLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0GUlEQVR4nO3debj19bz/8edLRSgVJak0kCFzRTlCGRo1SCVS6UiGzBw6pqiDzD9zosiYcCTKEEfmoYQIKSnNpTTI0PT+/fH5bJbtHvZde++1v/t+Pq5rX3ut7/qutd573ete+7U/Y6oKSZKkIbrVuAuQJEm6uQwykiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsAwy0oAlWTdJJVl2Fp7rsCSvnqbHuluSPydZpl8/Kcl+0/HY/fG+nGSf6Xo8SXOXQUaaBUnOSfLX/sv7T0mOT7L2uOuaMFLfNUmuTPL9JM9K8o/PiKp6VlUdMsXHeuyizqmqP1TVClV14zTU/tokH5/0+NtW1VG39LHHIcnjknyz/1tcnuRnSV6eZPlx1ybNRQYZafbsUFUrAGsAlwDvHnM9k+1QVSsC6wCHAi8HjpjuJ5mN1qMhmGiNmnRsN+CzwCeBdarqTsCTgLWAaQ++/ltoPjDISLOsqv5G+2W14cSxJCsl+WiSy5Kcm+RVE60hSW7Vr5+b5NJ+3koLeuwkT+wtIvdLsnySj/e/6q9McnKS1adQ31VVdRztF+g+Se7XH/sjSf6nX141yZf6416R5Du9zo8BdwO+2FufXjbS/fX0JH8A/m8hXWJ3T/LjJFcn+UKSO/bn2iLJ+ZN+znOSPDbJNsArgCf15/t5v/0fXVWLev1G6tgnyR+S/DHJKxf22vTX4LAkJ/YWk28lWWfk9nv3265IckaS3Sfd9/1JTkhyLbDlpMcO8Hbg4Kr6YFVd0f89zqiq51XVmSM/z4FJftf/bY8Zea0W+fP01qvP9vfF1cDT+nvviCQXJbkgyf8sKGRJc5VBRpplSW5HCwk/HDn8bmAlYH3gUcDewL79tqf1ry377SsA71nA4+4LvAl4bFX9EtinP+bawJ2AZwF/nWqdVfVj4HzgEQu4+SX9ttWA1WlhoqpqL+AP9NanqnrzyH0eBdwH2HohT7k38J+0FqsbgHdNocavAG8APt2f74ELOO1pLP712xy4F/AY4DVJ7rOIp90TOARYFfgZ8AmAJLcHTqS1ptwZ2AN4X5INR+77FOD1wIrAdyc97r1oLS+fW8RzAzwP2Jn2et4V+BPw3iX4eXaiBemVe+0fob3e9wAeDGwFTNt4JWmmGWSk2XNskiuBq4DHAW+Bf3Qx7AH8d1VdU1XnAG8D9ur32xN4e1WdXVV/Bv4b2GNSa8YLgf8Ctqiqs/qx62kB5h5VdWNV/aSqrl7Cmi8E7riA49fTAsc6VXV9VX2nFr9x22ur6tqqWliY+lhV/bKqrgVeDew+TS0DU3n9XldVf62qnwM/BxYUiCYcX1Xfrqq/A68EHpY23unxwDlV9eGquqGqfkoLJbuN3PcLVfW9qrqpt8yNWrV/v3jiQJKje6vXX5JMvB+eBbyyqs7vNbwW2HUJfp4fVNWxVXUTcAdgO+CF/d/mUuAdtPejNAgGGWn27FxVKwPLA88FvpXkLrRfYMsB546cey6wZr981wXctiytJWTCfwHvrarRLpiPAV8Fjk5yYZI3J1luCWteE7hiAcffApwFfC3J2UkOnMJjnbcEt59Le01WXci5S2Iqr9/FI5f/Qmu1WZh/1NmD0RX9OdYBNu3B48oeWvcE7rKg+y7A5f37GiOPv0d/z5wKTIS6dYDPjzzHr4Ebl+DnGa1hHdrrfNHI432A1qIkDYJBRpplvXXkf2m/fDYH/khr4Vhn5LS7ARf0yxcu4LYbaAOGJ2wFvCrJE0ee5/qqel1VbQj8B63FYO+p1pnkIbQgM7kLhN5y9JKqWh/YEXhxksdM3LyQh1xci83oYNa70V6TPwLXArcbqWsZWpfWVB93Kq/fkvhHnUlWoLVYXUgLCN+qqpVHvlaoqmdPsdYzaP/muyzm+c8Dtp30PMtX1QWLud+CajgP+Duw6shj3aGq7jvFx5LGziAjzbI0OwGrAL/uU5CPAV6fZMU+ePTFwMSU4k8BL0qyXv/FOTEm5IaRhz0d2AZ4b5Id+/NsmeT+/Rf/1bRgcNMU6rtDkscDRwMfr6pfLOCcxye5Rx+gehUtlE089iW0sShL6qlJNuxjiA4GPttfm98CyyfZvrcovQq4zcj9LgHWzchU8Umm8votie2SbJ7k1rSxMj+sqvOALwH3TLJXkuX610MWM97mH3pXz0uAg5I8I8kq/b2yAf/a2nIY7b2yDkCS1fr7aYlV1UXA14C39X/3WyW5e5JH3ZzHk8bBICPNni8m+TMtVLwe2KeqTu+3PY/W8nA2rQXkk8CR/bYjad1E3wZ+D/ytn/8v+niIxwMfTLItrUvjs/35fg18qz/Oouq7hvZX+itpM2j2Xci5GwBfB/4M/AB4X1V9s9/2Rlrr0JVJXrqI55vsY7SBpxfTut+e33+uq4DnAB+itVhcSxtoPOEz/fvlSU5dwONO6fVbAp8EDqJ1KW0MPLXXeQ2tZWwPWgvNxbTB17dZ8MP8u6r6NLB7f8zzaC1SxwCH88+f853AcbRuvWtog8Y3vQU/z97ArYFf0QYOf5aR7i1prsvix+dJkqBNoQbOr6pXjbsWSY0tMpIkabAMMpIkabDsWpIkSYNli4wkSRqseblh2KqrrlrrrrvuuMuQJEnT5Cc/+ckfq2q1ycfnZZBZd911OeWUU8ZdhiRJmiZJzl3QcbuWJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYBlkJEnSYC077gKkqVr3wOPHXcKgnHPo9uMuQZJmnC0ykiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsJx+LUlznEsPLBmXHli62CIjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGa8aCTJK1k3wzya+SnJ7kBf34HZOcmOTM/n2VfjxJ3pXkrCSnJdlo5LH26eefmWSfmapZkiQNy0y2yNwAvKSqNgQ2Aw5IsiFwIPCNqtoA+Ea/DrAtsEH/2h94P7TgAxwEbAo8FDhoIvxIkqSl24wFmaq6qKpO7ZevAX4NrAnsBBzVTzsK2Llf3gn4aDU/BFZOsgawNXBiVV1RVX8CTgS2mam6JUnScMzKGJkk6wIPBn4ErF5VF/WbLgZW75fXBM4budv5/djCjk9+jv2TnJLklMsuu2x6fwBJkjQnzXiQSbIC8DnghVV19ehtVVVATcfzVNXhVbVJVW2y2mqrTcdDSpKkOW5Gg0yS5Wgh5hNV9b/98CW9y4j+/dJ+/AJg7ZG7r9WPLey4JElays3krKUARwC/rqq3j9x0HDAx82gf4Asjx/fus5c2A67qXVBfBbZKskof5LtVPyZJkpZyy87gYz8c2Av4RZKf9WOvAA4FjknydOBcYPd+2wnAdsBZwF+AfQGq6ookhwAn9/MOrqorZrBuSZI0EDMWZKrqu0AWcvNjFnB+AQcs5LGOBI6cvuokSdJ84Mq+kiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsGZyZV9JkgZt3QOPH3cJg3LOodvP+nPaIiNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgbLICNJkgZriYJMklWSPGCK5x6Z5NIkvxw59tokFyT5Wf/abuS2/05yVpIzkmw9cnybfuysJAcuSb2SJGl+W2yQSXJSkjskuSNwKvDBJG+fwmN/BNhmAcffUVUP6l8n9OfYENgDuG+/z/uSLJNkGeC9wLbAhsCT+7mSJElTapFZqaquBnYBPlpVmwKPXdydqurbwBVTrGMn4Oiq+ntV/R44C3ho/zqrqs6uquuAo/u5kiRJUwoyyyZZA9gd+NI0POdzk5zWu55W6cfWBM4bOef8fmxhx/9Nkv2TnJLklMsuu2waypQkSXPdVILMwcBXaS0jJydZHzjzZj7f+4G7Aw8CLgLedjMf599U1eFVtUlVbbLaaqtN18NKkqQ5bNkpnPONqvrMxJWqOjvJS2/Ok1XVJROXk3yQf7bwXACsPXLqWv0YizguSZKWclNpkflikjtMXOmDbb94c56sd1FNeAIwMaPpOGCPJLdJsh6wAfBj4GRggyTrJbk1bUDwcTfnuSVJ0vwzlRaZN9DCzPbAvYCPAnsu7k5JPgVsAaya5HzgIGCLJA8CCjgHeCZAVZ2e5BjgV8ANwAFVdWN/nOfSuraWAY6sqtOX4OeTJEnz2GKDTFUdn2Q54GvAisATquq3U7jfkxdw+IhFnP964PULOH4CcMLink+SJC19Fhpkkryb1nIyYSXgd7RZR1TV82e6OEmSpEVZVIvMKZOu/2QmC5EkSVpSCw0yVXXUxOU+0Pae/eoZVXX9TBcmSZK0OIsdI5NkC+Ao2uDcAGsn2aev3CtJkjQ2U5m19DZgq6o6AyDJPYFPARvPZGGSJEmLM5V1ZJabCDEAfcbScjNXkiRJ0tRMpUXmlCQfAj7er+/Jvw8EliRJmnVTCTLPBg4AJqZbfwd434xVJEmSNEVTWRDv70neA5xIW1fGWUvSUmjdA48fdwmDcs6h24+7BGmp4KwlSZI0WM5akiRJg+WsJUmSNFjOWpIkSYPlrCVJkjRYU5q1BLy9f0mSJM0ZCx0jk2SDJB9J8vYkayX5cpI/J/l5kofMZpGSJEkLsqjBvh8Gvg9cCPwIOBJYFXgp8J6ZL02SJGnRFhVkVqiqw6vqrcBfq+ozVfW3qjoRuM0s1SdJkrRQiwoyN41cvnoRt0mSJI3Fogb73jvJabTVfO/eL9Ovrz/jlUmSJC3GooLMfWatCkmSpJthoUGmqs6dzUIkSZKW1FS2KJAkSZqTDDKSJGmwFrUg3jf69zfNXjmSJElTt6jBvmsk+Q9gxyRH02Yr/UNVnTqjlUmSJC3GooLMa4BXA2vx7/ssFfDomSpKkiRpKhY1a+mzwGeTvLqqDpnFmiRJkqZkKrtfH5JkR+CR/dBJVfWlmS1LkiRp8RY7aynJG4EXAL/qXy9I8oaZLkySJGlxFtsiA2wPPKiqbgJIchTwU+AVM1mYJEnS4kx1HZmVRy6vNAN1SJIkLbGptMi8Efhpkm/SpmA/EjhwRquSJEmagqkM9v1UkpOAh/RDL6+qi2e0KkmSpCmYSosMVXURcNwM1yJJkrRE3GtJkiQNlkFGkiQN1iKDTJJlkvxmtoqRJElaEosMMlV1I3BGkrvNUj2SJElTNpXBvqsApyf5MXDtxMGq2nHGqpIkSZqCqQSZV894FZIkSTfDVNaR+VaSdYANqurrSW4HLDPzpUmSJC3aVDaNfAbwWeAD/dCawLEzWJMkSdKUTGX69QHAw4GrAarqTODOM1mUJEnSVEwlyPy9qq6buJJkWaBmriRJkqSpmUqQ+VaSVwC3TfI44DPAF2e2LEmSpMWbSpA5ELgM+AXwTOAE4FUzWZQkSdJUTGXW0k1JjgJ+ROtSOqOq7FqSJEljt9ggk2R74DDgd0CA9ZI8s6q+PNPFSZIkLcpUFsR7G7BlVZ0FkOTuwPHAUhlk1j3w+HGXMCjnHLr9uEuQJM1jUxkjc81EiOnOBq6ZoXokSZKmbKEtMkl26RdPSXICcAxtjMxuwMmzUJskSdIiLapraYeRy5cAj+qXLwNuO2MVSZIkTdFCg0xV7TubhUiSJC2pqcxaWg94HrDu6PlVtePMlSVJkrR4U5m1dCxwBG0135tmtBpJkqQlMJUg87eqeteMVyJJkrSEphJk3pnkIOBrwN8nDlbVqTNWlSRJ0hRMZR2Z+wPPAA6lLY73NuCti7tTkiOTXJrklyPH7pjkxCRn9u+r9ONJ8q4kZyU5LclGI/fZp59/ZpJ9lvQHlCRJ89dUgsxuwPpV9aiq2rJ/PXoK9/sIsM2kYwcC36iqDYBv9OsA2wIb9K/9gfdDCz7AQcCmwEOBgybCjyRJ0lSCzC+BlZf0gavq28AVkw7vBBzVLx8F7Dxy/KPV/BBYOckawNbAiVV1RVX9CTiRfw9HkiRpKTWVMTIrA79JcjL/Okbm5ky/Xr2qLuqXLwZW75fXBM4bOe/8fmxhx/9Nkv1prTnc7W53uxmlSZKkoZlKkDloJp64qipJTePjHQ4cDrDJJptM2+NKkqS5a7FBpqq+NY3Pd0mSNarqot51dGk/fgGw9sh5a/VjFwBbTDp+0jTWI0mSBmyxY2SSXJPk6v71tyQ3Jrn6Zj7fccDEzKN9gC+MHN+7z17aDLiqd0F9FdgqySp9kO9W/ZgkSdKUWmRWnLicJLSBuZst7n5JPkVrTVk1yfm0LqpDgWOSPB04F9i9n34CsB1wFvAXYN/+3FckOYR/7rZ9cFVNHkAsSZKWUlMZI/MPVVXAsX2BvAMXc+6TF3LTYxbyuAcs5HGOBI5ckjolSdLSYSqbRu4ycvVWwCbA32asIkmSpCmaSovMDiOXbwDOoXUvSZIkjdVUxsjsOxuFSJIkLamFBpkkr1nE/aqqDpmBeiRJkqZsUS0y1y7g2O2BpwN3AgwykiRprBYaZKrqbROXk6wIvIA2Lfpo2g7YkiRJY7XIMTJ99+kXA3vSNnncqG/eKEmSNHaLGiPzFmAX2v5F96+qP89aVZIkSVOwqC0KXgLcFXgVcOHINgXX3IItCiRJkqbNosbILHYfJkmSpHEyrEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEyyEiSpMEaS5BJck6SXyT5WZJT+rE7JjkxyZn9+yr9eJK8K8lZSU5LstE4apYkSXPPOFtktqyqB1XVJv36gcA3qmoD4Bv9OsC2wAb9a3/g/bNeqSRJmpPmUtfSTsBR/fJRwM4jxz9azQ+BlZOsMYb6JEnSHDOuIFPA15L8JMn+/djqVXVRv3wxsHq/vCZw3sh9z+/H/kWS/ZOckuSUyy67bKbqliRJc8iyY3rezavqgiR3Bk5M8pvRG6uqktSSPGBVHQ4cDrDJJpss0X0lSdIwjaVFpqou6N8vBT4PPBS4ZKLLqH+/tJ9+AbD2yN3X6sckSdJSbtaDTJLbJ1lx4jKwFfBL4Dhgn37aPsAX+uXjgL377KXNgKtGuqAkSdJSbBxdS6sDn08y8fyfrKqvJDkZOCbJ04Fzgd37+ScA2wFnAX8B9p39kiVJ0lw060Gmqs4GHriA45cDj1nA8QIOmIXSJEnSwMyl6deSJElLxCAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGazBBJsk2Sc5IclaSA8ddjyRJGr9BBJkkywDvBbYFNgSenGTD8VYlSZLGbRBBBngocFZVnV1V1wFHAzuNuSZJkjRmQwkyawLnjVw/vx+TJElLsVTVuGtYrCS7AttU1X79+l7AplX13JFz9gf271fvBZwx64WO16rAH8ddxFLK1368fP3Hx9d+fJbG136dqlpt8sFlx1HJzXABsPbI9bX6sX+oqsOBw2ezqLkkySlVtcm461ga+dqPl6//+Pjaj4+v/T8NpWvpZGCDJOsluTWwB3DcmGuSJEljNogWmaq6Iclzga8CywBHVtXpYy5LkiSN2SCCDEBVnQCcMO465rCltlttDvC1Hy9f//HxtR8fX/tuEIN9JUmSFmQoY2QkSZL+jUFGkiQNlkFmAJJk9LskzbQkdxp3DdJUGGTmuCSpfw5kWm6sxSylRgOkYVJLgyTrA69Ist24a1na+Bmz5AYza2lpNRFi+srFmyc5A/hVVX1+vJUtPaqqkmwG/L6qLpkULjXDktwdoKp+N+5aliJ/A64FHpnk+qo6cdwFLQ1GP1uSPAg4E7ipqv461sLmOFtkBiDJfsCewLuAxwL/Md6Klkp7Ae+Bf4ZLzaw0twMOBrYYczlLhYnWgKq6EPgAcA2wbZLHjbWwpcCkEPMc4PPAR4D9k6wxztrmOoPMHDSpK2Ml4LbAk4EHAtcD/53kVknWGlOJ894CmncPAS5Oss5Cbtc0q+YvwEeBpydZb9w1zWeTfpGuXFUXAG8DLsMwM+NGXvtdgPsDmwKfANYA9jXMLJxBZo6Z9GGyP7A7sArwY2DXqtqqqm6gbZC5XZJlxlft/NW7k7ZMskuSdarqYuAOtH8PW2VmWJL1kzw6yZ2q6qvA94A799t8z8+Akc+d5wNHJjkGeCqtJfhy4DFJth9jifNeH2D9WmCDqrq0qo4FvgWsBByQ5C5jLG/OMsjMMSMfJo8GHg78L/BO2gf5af22fYDnAt+pqhvHVOq8NDJD7HbAjbSWsEOSHEhbSXPHJGsv4iF0M4289o8D3go8HvjfJA8EVgZeAOB7fuYk2QvYCXgGcB2wY1VdCxwB3AA8rP/f0DRIcqvRy1V1ObAvsFaSVwJU1ZeB7wM30VrkNYkr+84Rk1pi7gL8GvgusAttUPZGwLNpW7cvDzy3qn45pnLnpYl/gyTbAAcATwBuD9wOeAdwJbA3sEtVfaV/8Nw0toLnoSQPA14PvLKqfpDkWcB6/WtL4ClVdaIDrmdGDzKn0sbibQvsQAv0dwH+DCzXf9lqGiV5Cq076Vzgy8AKtDFKx1fVG/s5t++hUpMYZOaYJPcHfkXrHz0KeFVVfXrk9jsAN/qGnhm9JewwYL+q+naS5avqb721YDXgWbRwuXlV/Xmctc43ffzRO4HfVdVLRo6vSPtF+jrg3Kr67zGVOG8l2Rv4OrAVrTXs21W1S79tf+DewMuryhaBaZbkP4EXA2+itYadBRxHG2j9WeADVfX28VU499m1NEf0GRrrAK8Ang/8kNa8e2iS3SbOq6qrDTHTr7/+ywKbAa8GTu1/nZ6Y5GV94OmlVXUwrYtvlXHWO0/divYhvkWS0Zl5f62qM2n/H7ZIsuZYqpvfNqL90fQR2ua8Kye5a5IDgOcBHzLETI8kmya5fb98G2AT4AVV9TFaoLkW2LqqfgHsRpu9pEUwyMwR/RflucCngPsAB1TVSbT+0g8l2XmM5c1bI9NNqw+i/jXwfuBzwJr98h5JNujnPxR4KGBT5i00MiZmkySPBQK8Efg0sFd/ren/LgD3Be4IuKbG9PsgUElWqaq9gXNoM/UeCzypqn41zuLmme2BOyRZtqr+DlwBPKW/9n+gffZs0Qe6n1ZVvx9rtQNg19IckGQLYOeqemG/vh2wB/Czqnp7ks2Bi6vqrLEVOQ+NjIl5JC2c/KCqvpdkQ+Cqqrqg//X/OdqH+bl9/FKq6qJx1j5fJNka+H/Ah4D/oXVtXEobm3F/4P1V9cN+7nq0xcHOHU+180uSp9HG332KFg6PoLV+PWfknFtX1XXjqXB+mTQO8r7AJ4FHAmsDTwPOpwXKLWmtYLtW1TXjqXZYbJEZgySrJVmlX35YP3yXJAcDVNUJwA+A5yV5RlV91xAz/XqI2R54H62F5U1JDgL+3kPMk4ETgTf1EJOqutgQc8v1rrxVaR/YOwA/As4GflNVZwDHAL+lDTAFoKp+b4i5+SZawEacR/uD6X9osyBfDKyZ5METJxhipkeS1YF1++Udqup04Je0dWLOp33O3JvWrfdy2ngkQ8wU2SIzBkkeAbwM+ClwD+BFwDq0D5PzquqVSbaldSs9v69homkw6a+iNWhrZLyU9iHybtoHyh9pXUrrAytW1VedJXPLJVkeuG1V/al/sF8JPIc2tXob2oyk3yXZE/ga8KeRbiXdApPe9zvQplJfVlWnJNmE1o10A22szCFVddj4qp1/kjyA9pnyM9rK7I+sqmuSfIzWXfqUqrqqtzpeWVV/Gl+1w2OQGZMkxwKPAXaoqpP64K/7AIfSplffkTbN9zfjq3J+6etfrNZbVx5EGw9zV9r06o/Q1i15GG0106OBg/xFOj36ehkPpb2+fwE2B14F/DfwOODR/d/lwbQm96dV1Y/GVe98M9KN+hzaoOkTaLPvPldVr+rnPIE2Jub9Lu0wPSYFyINprS1Pr6qPj5zzEdqq7Y+qqqvHUujAGWRmyeS/6PuUxnvS0vl+E4PpktyW9oH/+z7wS9Mkyf1orV4XAM8EHltVv+kDTZ9fVTsm2Yj2C/YVhsjplWRd2vTqzYD/qqqP9paZzwCn0wb7Pgx4dVUdN7ZC55EkdwMur6prk9yZ1mX37Kr6de/ePhl4b1W9o59vy+M0mRRiNqVNHlgZOJA2S+nLI+e+ATi8qs4ZQ6mD5+7Xs2DSG3pz2hiMw/v1VwNHpa1mugmwZlUdNb5q56+q+mWSS+ktASNB5dvA4Um+CGwIPM8QM33SFw6sqnOS/JA27uU+SR5QVaf1btSJfXw+XFU/8hfqLddD4kuA85IcVlWXJvkjbcVeehffixjZhNbXfHpM+sx/KX0Ab1WdneQ64D1pyzs8ALhXVb1ojOUOnkFmFoy8oZ8PPAU4Pcl7aV1Hh/RBeCfT1g/YY3yVzk+TfikeA1xN2zfm17SFv67tXRqPAS6wS2P69Nf+pj4uY6eq2i/JvWi7ue+X5BDapINrquobE/fzF+q0uIz2ubIRbdPB99DW6Tk6ycN6t+m6wNpJlim3fpg2I5/5jwCeCGxbVVf22z6e5CbgNbQNgV8wrjrnC7uWZtCkVL4VbUDd5rQF7w4EzqQN8jqnD7i7qNqOs5pmSR5DWy35W9WmWO9BGytwEG3F3kdU1YvHWeN81WeGHUrrTvpKP3ZPWqh/KG2a9VOq6jvjq3L+SFvz6FZVdUb/I+nxtO0GflZVhyd5P21Mxmm0/xN7luvETIu0pRueMdHC0j/396uq3dM3O50IjGkrVt+qqq4aW8HzhEFmhkwKMVvQ/jJaCdga2L2qtk3yJdpsmUc7Hmb6jQxw3IS2PsPPaK2QP6etXbIbsDOwAW2K9acX/EhaUpPe/28GjgXOAB5B26/qbbTp1g8E/lJV3x5TqfNK2u7Jl9Fm3r2Otk/S4bTQeA/aH0sf6GM2lgf+UC64Ni36sIELgT8B9+xdpHen7R32auDsqrqxz8q7E21skq1g08CupRky8iH+VFoLzPZVdWGSewPH99OOp82Y8c08A3qI2Zi24eMzq+rHvYtjS+CFwHuBL9GmWF/ouIzp01/7/6CtVXIlbf+eP9PGI11Em6305IkWGk2Pqrq8D17/Oq3L7oG0lZL/TBsbc//eSvPhaqvKahr0MY5HAk/s42AO7GPDdkryG9r7/fdJrqFtSPt4Q8z0McjMoCSb0d60L6iqy/oU1DOALXsT5ESTut1JM6dor/OewI+r6otJbqQ1t78YeHP1hacMMdPuCcDdqupJSX4O/Lp/yK9NWwhsZdrGeJpGVfV/aSsmv4sWZFYHHk0bf/dQ4F601XwNMtOg/3F0EG3M48lpG/s+FzgkyYerat8kOwIPpo1J2rHaoo+aJnYtTaMFTLHeFnglrQn9mVX1197U+CBgC+Cwais8apqMdCetQHt/X9Ob0d8PfKqq3tLP2wE4q6p+Pc5655MFvP/vRFs19g1VdV4/tiutmf21VeVmeDOoj016B7BZVV3Rp1svB9zOab7TI8lytG7TVatq0/6eP5rWrfdzWpf236tqn37+suXaVNPOIDNNJo0JeBBwQ5/u+whgV9r+MW+rqr+Nscx5bSTE7ERbJ2ZZ4INV9Zk+TuZdwJer6pCxFjrPpK1VsnYfRL0lbe+Y71VbpfcDwCVV9Zp+7guBX1XV1+zKm3n9j6l3Ag+rqsvHXc98lLY+z7uBWwOrAh+rfy6vcQfg47S92/byPT8zDDLTrH9QP4E22G4FYD/arr1b0zZme51909Orz4BZr9pWAlsBbwB2pM0M2xd4YVUdMdIysyttwUHf/LdAH2uxIq279Cpgf9rU9gNp4zH+ABxHaxXYu6p+N6ZSl2o92L8W2LiqbhpzOfNS2r5hHwbWqaoH9GO3rqrr+uykFavqwrEWOY+5aeQ06q0vW1fVo2izlJatqvP6gMav0Zp1VxhnjfNNDzHHAmv0Q3ei9U8/hDY+YH/gzUmeW219mC2q6mxDzC1XzdW07R3OA14BrFJVe9DWxlibFiQ3pnWnTmxVoFlUVV+gLS9giJkhVfVH2nv9rCRH9WPX9fV5rjHEzCxbZG6BJCtU1Z/75dsDd6a1vKxLW4Rq+6q6PslWvSn9tlX11/FVPL/0AdOfoI23+EJvIVgXOAf4AnBoVX0/bWO2zWgf5m7AOQ2SLFdV1/fLW9OmsX+Z9mH+qao6pt92J2Av2po9j6iqK8ZTsXTLLa5rqLfMvB9Ypqp2mb3Klm7+dXQzpe3k+5gkT0zyTODZtNkBe9L+At26h5inAf+T5E6GmGl3R+CB/S9OaBvhPaF/0PwOeFQfI7AsbXaYIWYa9CUEjujjYaC1Nq5EC4tHAXsleSK06cBV9f+AU2izlKRBmjQOcrUeWv5Fb5k5ALg2yV1nu8alldOvb4Ykd+8DGS8H3kP7gH54VV2Q5AhaqHl5/2t0a9p6GQ60m2ZV9d0k2yc5mxZcvldVb+83/4i2auk7gJdV1cnjqnMeujPwVOC+SQ4DbqKvC0N73ZcHDkhCVX2ur+WzCeBsDQ3WSIh5KfBw4C5JPkHb7PG6kfMuTbKPXXmzx66lJdC7LlagLaT2LNo+GccB5wNfAY6qtq/MNrQxG6sBn6+qM8dU8lIhbfuBrwC3ntzsm+QuVXWxswWmV9oqpl8FdqdtOvho2u6+TwR+Sls1+cyqOqX/5bpMVV0yrnql6ZBkF2D/qtomyTG036G7jbuupZ1BZgkkWaOqLkpyG9qeSRtV1Vt6E/uewGlV9a7e9H5VVV001oKXIkm245/TTP84OoZDM6OPjfl/tB18HwxsQ2sV+8bEehnpO1+Ps07p5lrA2ki70loW7wM8CtihDyG4u7PyxseupSnoLTErAWcmeWFVfSjJFcBT+/v8rX2K3Y5p+yetRpuCrVlSVSekrdh7epJ7V9Wfxl3TfNenu7+UtvngZtW2gFiu33ZD/26I0SBNGhOzZVV9EwhteYELaZM5bkzyAmCLJE+mLX5n68AsM8hMQX9jXtlXg/1Mkuuq6qNp+yh9qP/V+eYkv6WtUfK/Trebff0X63/Spl2fNOZylgpVdXwPkL81QGo+GQkxzwH2662+n6PN0PsbsFXaSu1Pp42DdLHTMbFraYommsiTPBL4IvC8HmYeQJtud1JVvXK8VWqCY2JmV9py+NdW1UnjrkWaLmkbn76X1oV0fj+2LG2BweVpMyffUm51Mla2yExRDzG3qqpv95aZL/ZZGR9N8lzaomurAX/0F+j4+W8wu6rqeDBAat65PW3s4/l9Mcdl+wylV8E/V+8da4VyHZmF6eNi/uX6aJgBdgDenmT/qvoprb/0Mj/EtTTz/a+hGv3M7+uEAfwauEeSnavqpr5a77OTvKbf7oSCOcCupQWYNMhrR+D/Jlbw7ceW6YO8HgMcSZu1cbUf4pI0PJM+8/cDHgl8m7aT9c7AVrRlNn5PW3pjr6r61Xiq1WS2yCxCkgOAQ4G7TLrpph5mvgHcu6quMsRI0jCNhJjdgb2BE4FnAk8DTgXeRZuNuj6wjyFmbrFFZkSSdavqnH754bQ377Z9pcbNgMuB82tkqwHHBEjS8CV5CPBW4PXV9sZ7MHAQ8B3a6r3XjLVALZQtMl2SOwD/leQV/dBVwHeBfZO8gzZy/TDa1N5/MMRI0vBMHgdJm4V0DfCMJHfuYx9fAzwe+M8ky8x2jZoag8w//RX4OLB2X9joDOBa2kaQn6mqjYFfAg8dX4mSpFtq0piYzZJsCvwQeDVwNvCiJKtV1WnAc4HPVdWN46tYi7LUdy1NekMvB9wTuKTaLqaj5+1Km3K3m3snSdLwLGDLgefT9gs7A9iItiL73YDtgNsBB0/+XaC5Z6lukZkUYtYGVqyq0/tePbceOW9b4Bm0keqGGEkapjtOXOitMFtV1ea0bTaurKpz+vIaX6J1M03uftIctNS2yEwKMS+hjVQ/F/h+VR3aj0+s5rsMsIrJXJKGqf+x+lLg5VX1t379icDawP1pa4Fdn+SJVfW5JLepqr+Ps2ZNzVK7su9IiHko8BBgF+AOwIf7ao0H9xAzsYuyIUaShutK2vCABydZCfg+bWHT2wCP6muD7UUbH/Odqrp0fKVqSSy1LTIASTamLWj3g6p6Vj92b+CTwNeq6sBx1idJumUmWtZHrj8f2BF4Ee2P+SOArwAr0hbC27OqfjmOWnXzLFVjZCZPt6uqn9CmVW+YZOMky1bVb4C9gM2TrLqAKXqSpAGY2FqmX35qknsAHwU+BbyJtov1bsAvgN8CuxhihmepbJHpS1CvQZty/R7aCo6PBQ4GflpVN4x0KUmSBizJc4Bn02ad/ibJyrTZSo8H3lFV3xxnfbpllqoWGYAkLwT2AL5HG+D7nKp6J23xu7fT9k3CECNJw5TkdiOX1wKeDDy+h5hU1ZXA54CvA89Kcntb34dr3geZSTua3pq2b9LjaGsGnAe8t++b9Cbg08BlYylUknSLJdkOeEOStfvn/zK0adSX9FMmJrkU8D7gmVV1rau0D9e87loaHeSVZG/gOlp/6MrAn4Cn9G3ZnwX8rqpOHFuxkqRbJMnjgdcDB1XVsSPHPw5cW1XP7NefDuwE7FpV142jVk2feT39eiTEPBx4WlU9Osn5wFHAYT3E7AO8ANh+jKVKkm6BJHcBXgLsV1Un9xb45Wkr9L6Rtm/eKcAXgZ2BvQ0x88O8DDJ9CvUDgM8CDwLeTVszAODHwMuAtyTZHrgfLZWfPYZSJUnT4+/A9cDfkiwPHAhsTutaOgd4MfBz4M/Ap6rqt2OqU9Ns3gWZJMsCWwP3Aa6rqmOTHA88LMm9+/TqzyX5EXATcIMLH0nS4F0JfBV4K3Bf2kDeo2mb/T4H2LSqPja26jRj5tUYmUljYl4HrAV8vKq+meTNtM3AXguc6U6mkjS/JFmBtt3A2sAXJrYYSHIEcJJBZn6aV0FmQpIDaAO5VgEuoo2HOSHJobQupxe4+aMkzX9JdgNeDjypqn437no0/eZF11KS21fVtf3yhsA+wGa0PTT2B3ZOcm1VHdhbav4yvmolSTMtyRrAk4BnYIiZ1wa9jkya9YBTktyvH76BFmDWr6q/Ah8G7gy8PsnjquqgqrpgTCVLkmbHlcCZwE5uOzC/DTrIALerqt8DxwAfT3K/PhL9S8AOSdavqquB/wN+QxuxLkma56rqr1V1fFWdNe5aNLMGO0YmyX2A/wReXlU3JTkQeCqwC3BH4AnApsDJtDVidnJcjCRJ88tggwxAkjsBGwDXVNXpSV5B2whsV9py1I+ljV7/imsGSJI0/wwuyEzsnTSxL0aSw2k7Wb+0qs7oYWZX2kq+p42vUkmSNNMGF2QmJFm9qi7pl19PWwDvFX1304NpG0M+CrjezcAkSZqfBhNkkmwELFdVP0ryPOApwCm0NWJOT/IGWjfTa/v1O1XV5eOsWZIkzaxBzFrq2w48nLY1+wuBRwPPpdX/jCT/UVWvAC4EDkyyHHDFuOqVJEmzY84viJdk437xm7TNvvajLT39kyRn03au3j3JslX1giSrVdX146pXkiTNnjndIpNkG+ADtPEv1wLHAV+mbcf+sKr6E/A22o6n2ydZvqouG1vBkiRpVs3ZMTJJHgV8CHhKVZ08cnwV2noxWwFvqKof9I3Clq+qP46nWkmSNA5zOci8GLixqt7Zu41uGLltVdqCd3vRpl3/eFx1SpKk8ZlzY2SSpE+XXg+4qh++cdJtqwHf67ddNPtVSpKkuWDOjZEZWfPl88BmSTauqkpyKyD9tscAywBHVNV546hTkiSN35wLMiN+BHwXeFIPMzf1PZX2AJ4GXFVVN421QkmSNFZzdowMQJI1gafTWmBOAf5K235gV7dllyRJczrIACS5LbAxbQPIi4BvugGkJEmCAQQZSZKkhZnLY2QkSZIWySAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjSZIGyyAjaU5IsnqSTyY5O8lPkvwgyRPGXZekuc0gI2nskgQ4Fvh2Va1fVRsDewBrTcNjL3NLH0PS3GWQkTQXPBq4rqoOmzhQVedW1buTLJPkLUlOTnJakmcCJNkiyUlJPpvkN0k+0QMRSc5J8qYkpwK7Jdmqt/CcmuQzSVYYz48paboZZCTNBfcFTl3IbU+nbRL7EOAhwDOSrNdvezDwQmBDYH3g4SP3u7yqNgK+DrwKeGy/fgrw4mn/CSSNxbLjLkCSJkvyXmBz4DrgXOABSXbtN68EbNBv+3FVnd/v8zNgXeC7/bxP9++b0YLO93qDza2BH8z4DyFpVhhkJM0FpwNPnLhSVQckWZXWevIH4HlV9dXROyTZAvj7yKEb+dfPtGsnTgVOrKonT3/ZksbNriVJc8H/AcsnefbIsdv1718Fnp1kOYAk90xy+yV47B8CD09yj37/2ye553QULWn8bJGRNHZVVUl2Bt6R5GXAZbQWlZcDn6F1GZ3aB/NeBuy8BI99WZKnAZ9Kcpt++FXAb6erfknjk6oadw2SJEk3i11LkiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsAwykiRpsP4/Or4l35G+c8UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.title('Books Distribution per Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Number of Books')\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.bar(books_distribution_df.index, books_distribution_df['title'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the bar chart, it is revealed that the class of the dataset is not too uniformly distributed. The bar chart shows fantasy is the most common genre in the dataset, followed by novel. On the other hand, books with children's literatures genre are the least common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Measure the Models Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF with default parameter\n",
    "\n",
    "The first stage of the this experiment is to get the summary of each book from dataset and transform it using TF-IDF method. The transformation is needed because the models cannot get raw text as input. All of the models in this stage use TF-IDF transformed text with default parameter as input.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to stem sentence\n",
    "porter=PorterStemmer()\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "# stem book summary\n",
    "genre_books['text_stemmed'] = genre_books.summary.apply(stemSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train data and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(genre_books.drop(['genre'], axis=1), genre_books.loc[:,'genre'], random_state=69,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5143     Children's literature\n",
       "9826     Children's literature\n",
       "11164    Children's literature\n",
       "8682     Children's literature\n",
       "924      Children's literature\n",
       "                 ...          \n",
       "13820    Children's literature\n",
       "1957     Children's literature\n",
       "13090    Children's literature\n",
       "4232     Children's literature\n",
       "13284    Children's literature\n",
       "Name: genre, Length: 218, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test == \"Children's literature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the train data and test data using tfidf\n",
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(X_train.summary)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test.summary)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Multinomial Naive Bayes Model accuracy score is 0.56, the confusion matrix is below \n",
      "\n",
      "[[  0   0   0   0   0]\n",
      " [ 95 401  52  45 101]\n",
      " [  0   1  27   0   2]\n",
      " [123  47 197 389  77]\n",
      " [  0  18   2  21 193]]\n",
      "\n",
      "The Logistic Regresion Model accuracy score is 0.71, the confusion matrix is below \n",
      "\n",
      "[[ 90  11  10   5   5]\n",
      " [ 45 362  18  27  50]\n",
      " [ 10   7 186  17   9]\n",
      " [ 69  43  57 363  45]\n",
      " [  4  44   7  43 264]]\n",
      "\n",
      "The KNN Model accuracy score is 0.52, the confusion matrix is below \n",
      "\n",
      "[[ 66  16  18  24  11]\n",
      " [ 28 224  20  30  42]\n",
      " [  4   3 134  13   5]\n",
      " [100 179  93 345 146]\n",
      " [ 20  45  13  43 169]]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "\n",
    "print('The Multinomial Naive Bayes Model accuracy score is %.2f, the confusion matrix is below \\n' %(accuracy_score(predicted, y_test)))\n",
    "print(confusion_matrix(predicted, y_test))\n",
    "\n",
    "logisticRegression = LogisticRegression(max_iter=200).fit(X_train_tfidf, y_train)\n",
    "LR_predicted = logisticRegression.predict(X_test_tfidf)\n",
    "\n",
    "print('\\nThe Logistic Regresion Model accuracy score is %.2f, the confusion matrix is below \\n' %(accuracy_score(LR_predicted, y_test)))\n",
    "print(confusion_matrix(LR_predicted, y_test))\n",
    "\n",
    "KNNclassifier = KNeighborsClassifier(n_neighbors=10).fit(X_train_tfidf, y_train)\n",
    "KNN_predicted = KNNclassifier.predict(X_test_tfidf)\n",
    "\n",
    "print('\\nThe KNN Model accuracy score is %.2f, the confusion matrix is below \\n' %(accuracy_score(KNN_predicted, y_test)))\n",
    "print(confusion_matrix(KNN_predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three type of models are used in the first stage are Multinomial Naive Bayes, Logistic Regression and KNN. All of the models use TF-IDF transformed book summary with default parameter as input. The model with highest accuracy is Logistic Regression with accuracy score 0.71, followed by Multinomial Naive Bayes with score 0.56. The confusion matrix of Multinomial Naive Bayes shows interesting result regarding the predicted class. All of the elements in first row is 0 and it means the model never predicts the output to be class 1 which is Children's literature genre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF with Stop Words Parameter Enabled\n",
    "\n",
    "After the models training and measuring accuracy of the models in stage 1, the experiment continues with different treatment in CountVectorizer TF-IDF parameter. This time stop_words parameter is enabled and the training and measuring in stage 1 are repeated. The parameter enabling is expected to improve the accuracy of the three models because it removes common English words that are frequently used in a sentence, such as \"the\", and don't really give any meaningful input to the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the train data and test data using tfidf\n",
    "\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "tfidf_transformer = TfidfTransformer()                 \n",
    "\n",
    "X_train_counts_stop = count_vect.fit_transform(X_train.summary)\n",
    "X_train_tfidf_stop = tfidf_transformer.fit_transform(X_train_counts_stop)\n",
    "\n",
    "X_test_counts_stop = count_vect.transform(X_test.summary)\n",
    "X_test_tfidf_stop = tfidf_transformer.transform(X_test_counts_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Multinomial Naive Bayes Model using stop words accuracy score is 0.60 and the confusion matrix is below \n",
      "\n",
      "[[  0   0   0   0   0]\n",
      " [ 87 382  37  31  68]\n",
      " [  0   1  70   1   3]\n",
      " [131  58 167 390  73]\n",
      " [  0  26   4  33 229]]\n",
      "\n",
      "The Logistic Regression Model using stop words accuracy score is 0.71 and the confusion matrix is below \n",
      "\n",
      "[[ 92  11  13   8   5]\n",
      " [ 44 368  16  25  48]\n",
      " [  8   8 187  17  11]\n",
      " [ 70  39  56 361  46]\n",
      " [  4  41   6  44 263]]\n",
      "\n",
      "The KNN Model using stop words accuracy score is 0.56 and the confusion matrix is below \n",
      "\n",
      "[[ 98  48  32  68  25]\n",
      " [ 39 302  30  63  62]\n",
      " [ 17  22 162  50  25]\n",
      " [ 54  55  45 221  37]\n",
      " [ 10  40   9  53 224]]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf_stop, y_train)\n",
    "predicted = clf.predict(X_test_tfidf_stop)\n",
    "\n",
    "print('The Multinomial Naive Bayes Model using stop words accuracy score is %.2f and the confusion matrix is below \\n' %(accuracy_score(predicted, y_test)))\n",
    "print(confusion_matrix(predicted, y_test))\n",
    "\n",
    "logisticRegression = LogisticRegression(max_iter=200).fit(X_train_tfidf_stop, y_train)\n",
    "LR_predicted_stop = logisticRegression.predict(X_test_tfidf_stop)\n",
    "\n",
    "print('\\nThe Logistic Regression Model using stop words accuracy score is %.2f and the confusion matrix is below \\n' %(accuracy_score(LR_predicted_stop, y_test)))\n",
    "print(confusion_matrix(LR_predicted_stop, y_test))\n",
    "\n",
    "KNNclassifier_stop = KNeighborsClassifier(n_neighbors=10).fit(X_train_tfidf_stop, y_train)\n",
    "KNN_predicted_stop = KNNclassifier_stop.predict(X_test_tfidf_stop)\n",
    "\n",
    "print('\\nThe KNN Model using stop words accuracy score is %.2f and the confusion matrix is below \\n' %(accuracy_score(KNN_predicted_stop, y_test)))\n",
    "print(confusion_matrix(KNN_predicted_stop, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second stage transforms book summary with parameter English stop words enabled. Similar to the first stage, Logistic Regression has the highest accuracy score with 0.71, followed by Multinomial Naive Bayes with 0.60 and KNN with 0.56. Multinomial Naive Bayes accuracy increases from 0.56 to 0.60 and KNN accuracy also increases from 0.52 to 0.56. Unusual result of Multinomial Naive Bayes confusion matrix also happens in stage 2. All of the first row elements are 0 and this means Multinomial Naive Bayes never predicts the output to be children's literature genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF using Stemmed Text as Input\n",
    "In the first 2 stages, input text doesn't get any treatment or transformation before CountVectorizer and TF-IDF transformation. This stage transform the input text using Stem technique. The datacamp says \"[Stemming](https://www.datacamp.com/community/tutorials/stemming-lemmatization-python) is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language\". Transforming word into their stemmed version might be able to increase the performance of classification model because words that are different because of grammar's inflection are treated and categorised into the same word. For example, words like 'trouble', 'troubling', 'troubled' are transformed into 'troubl'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the book start where exil left off , with ben return to jacen aboard the sith medit sphere he found on ziost . the novel follow jacen as he manipul polit , introduc a new law that allow him to rewrit other law . use thi and cal oma ' betray to the galact allianc as leverag , he and admir niathal stage a bloodless coup , arrest oma and instal themselv as joint chief of state . at the same time , jacen send ben to assassin dur gejjen , throw the corellian-l confeder into chao . meanwhil , boba fett and mirta gev are still in search of a cure to fett 's ill after find kad skirata , the son of a clone . in exchang for the promis of make the mandalorian a unit peopl , he cure boba , give him anoth thirti or so year to live . ben overhear a convers between lumiya and jacen and , horrifi , confess all to hi mother , mara jade skywalk . mara , livid with jacen for attempt to turn ben to the dark side , set out to kill him . thi backfir , howev , as jacen kill mara as hi final sacrific . thi sacrific kill ben 's love for jacen , make the propheci complet . think that lumiya kill mara , luke hunt her down and kill her . ben then reveal that mara 's killer could not have been lumiya , sinc ben wa with her at the time . at the end of the book , jacen solo assum hi sith name : darth caedu . \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stem text example\n",
    "X_train.text_stemmed.iloc[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the train data and test data using tfidf\n",
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train_counts_stem = count_vect.fit_transform(X_train.text_stemmed)\n",
    "X_train_tfidf_stem = tfidf_transformer.fit_transform(X_train_counts_stem)\n",
    "\n",
    "X_test_counts_stem = count_vect.transform(X_test.text_stemmed)\n",
    "X_test_tfidf_stem = tfidf_transformer.transform(X_test_counts_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Multinomial Naive Bayes Model using stemmed input accuracy score is 0.56 and the confusion matrix is below \n",
      "\n",
      "[[  0   0   0   0   0]\n",
      " [ 89 390  52  34  87]\n",
      " [  0   1  25   0   2]\n",
      " [129  56 199 397  92]\n",
      " [  0  20   2  24 192]]\n",
      "\n",
      "The Logistic Regresion Model using stemmed input accuracy score is 0.71 and the confusion matrix is below \n",
      "\n",
      "[[ 90  11  10   5   5]\n",
      " [ 45 362  18  27  50]\n",
      " [ 10   7 186  17   9]\n",
      " [ 69  43  57 363  45]\n",
      " [  4  44   7  43 264]]\n",
      "\n",
      "The KNN Model using stemmed input accuracy score is 0.52 and the confusion matrix is below \n",
      "\n",
      "[[ 66  16  18  24  11]\n",
      " [ 28 224  20  30  42]\n",
      " [  4   3 134  13   5]\n",
      " [100 179  93 345 146]\n",
      " [ 20  45  13  43 169]]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf_stem, y_train)\n",
    "predicted = clf.predict(X_test_tfidf_stem)\n",
    "\n",
    "print('The Multinomial Naive Bayes Model using stemmed input accuracy score is %.2f and the confusion matrix is below \\n' %(accuracy_score(predicted, y_test)))\n",
    "print(confusion_matrix(predicted, y_test))\n",
    "\n",
    "logisticRegression = LogisticRegression(max_iter=200).fit(X_train_tfidf, y_train)\n",
    "LR_predicted = logisticRegression.predict(X_test_tfidf)\n",
    "\n",
    "print('\\nThe Logistic Regresion Model using stemmed input accuracy score is %.2f and the confusion matrix is below \\n' %(accuracy_score(LR_predicted, y_test)))\n",
    "print(confusion_matrix(LR_predicted, y_test))\n",
    "\n",
    "KNNclassifier = KNeighborsClassifier(n_neighbors=10).fit(X_train_tfidf, y_train)\n",
    "KNN_predicted = KNNclassifier.predict(X_test_tfidf)\n",
    "\n",
    "print('\\nThe KNN Model using stemmed input accuracy score is %.2f and the confusion matrix is below \\n' %(accuracy_score(KNN_predicted, y_test)))\n",
    "print(confusion_matrix(KNN_predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last stage used stem transformed text as input and the model with highest accuracy is Logistic Regression, followed by Multinomial Bayes Analysis and KNN. Multinomial Bayes Analysis still has peculiar confusion matrix that shows the model never predicts output to be class 1 or children's literature genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project shows that Logistic Regression Model is the best classifying model if the input is text based input. The accuracy score of Logistic Regression Model is consistently around 0.71 in all three different treatment of inputs. The three different treatments are transforming text using TF-IDF with default parameter, transforming text using TF-IDF with English stop words parameter enabled and transforming stemmed text using TF-IDF with default parameter. The best scores all achieved by all of three models when TF-IDF transform with English stop words enabled is used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
